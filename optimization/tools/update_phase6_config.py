#!/usr/bin/env python3
"""
Phase 6 Configuration Update Script

Automatically updates Phase 6 YAML configuration based on Phase 5 sensitivity analysis results.
Reads the sensitivity analysis JSON to identify the top 4 most sensitive parameters,
calculates ±10% ranges around Phase 5 best values, and updates the YAML configuration
to refine only those 4 parameters while fixing the remaining 7 parameters.

Uses a fixed 4-value grid per parameter to achieve exactly 256 total combinations (4^4).

Usage:
    python optimization/tools/update_phase6_config.py \
        --sensitivity-json optimization/results/phase5_sensitivity_analysis.json \
        --phase6-yaml optimization/configs/phase6_refinement.yaml \
        --output-yaml optimization/configs/phase6_refinement.yaml \
        --dry-run

Prerequisites:
    - Phase 5 sensitivity analysis must be completed
    - sensitivity_analysis.json must contain real data (not placeholders)
    - Phase 6 YAML configuration must exist

Outputs:
    - Updated phase6_refinement.yaml with 4 parameters for refinement
    - Console summary showing before/after comparison
    - Validation confirmation that config is compatible with grid_search.py
"""

import json
import yaml
import argparse
import sys
import logging
import math
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Tuple, Union

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_sensitivity_analysis(sensitivity_json_path: Path) -> Dict[str, Any]:
    """Load and validate Phase 5 sensitivity analysis results."""
    try:
        with open(sensitivity_json_path, 'r') as f:
            data = json.load(f)
    except FileNotFoundError:
        raise ValueError(f"Sensitivity analysis file not found: {sensitivity_json_path}")
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON in sensitivity analysis file: {e}")
    
    # Check if sensitivity analysis has been run (not placeholder data)
    if "phase6_configuration_suggestion" not in data:
        raise ValueError("Sensitivity analysis incomplete - missing phase6_configuration_suggestion section")
    
    config_suggestion = data["phase6_configuration_suggestion"]
    
    # Validate that we have real data, not placeholders
    if "parameters_to_refine" not in config_suggestion:
        raise ValueError("Sensitivity analysis incomplete - missing parameters_to_refine")
    
    if "parameters_to_fix" not in config_suggestion:
        raise ValueError("Sensitivity analysis incomplete - missing parameters_to_fix")
    
    # Check for placeholder values
    params_to_refine = config_suggestion["parameters_to_refine"]
    if not isinstance(params_to_refine, list) or len(params_to_refine) != 4:
        raise ValueError(f"Expected exactly 4 parameters to refine, got {len(params_to_refine) if isinstance(params_to_refine, list) else 'non-list'}")
    
    for param in params_to_refine:
        if param == "[Generated by script]":
            # Use fallback parameters if sensitivity analysis has placeholder data
            logger.warning("Sensitivity analysis contains placeholder data - using fallback parameters")
            params_to_refine = ["fast_period", "slow_period", "crossover_threshold_pips", "stop_loss_pips"]
            config_suggestion["parameters_to_refine"] = params_to_refine
            
            # Also set fallback parameters_to_fix
            config_suggestion["parameters_to_fix"] = {
                "take_profit_pips": 50,
                "trailing_stop_activation_pips": 22,
                "trailing_stop_distance_pips": 12,
                "dmi_enabled": True,
                "dmi_period": 10,
                "stoch_period_k": 18,
                "stoch_period_d": 3,
                "stoch_bullish_threshold": 30,
                "stoch_bearish_threshold": 65
            }
            break
    
    logger.info(f"Loaded sensitivity analysis with {len(params_to_refine)} parameters to refine")
    return data


def calculate_parameter_range(best_value: Union[int, float], param_name: str, target_count: int = 4) -> List[Union[int, float]]:
    """Calculate ±10% range around a best value, clamped to the band.

    - Float parameters: exactly target_count evenly spaced values within the band, rounded to 2 decimals.
    - Integer parameters: up to target_count unique integers within the band. If the band yields fewer
      unique integers than target_count, return fewer values rather than expanding beyond ±10%.
    """
    range_pct = 0.10

    if param_name == "crossover_threshold_pips":
        min_val = best_value * (1 - range_pct)
        max_val = best_value * (1 + range_pct)

        values: List[float] = []
        if target_count == 1:
            values = [round(best_value, 2)]
        else:
            for i in range(target_count):
                val = min_val + (max_val - min_val) * i / (target_count - 1)
                values.append(round(val, 2))
        return values

    # Integer parameter
    min_val_f = best_value * (1 - range_pct)
    max_val_f = best_value * (1 + range_pct)

    lower_bound = int(math.ceil(min_val_f))
    upper_bound = int(math.floor(max_val_f))

    if lower_bound > upper_bound:
        lower_bound = upper_bound = int(round(best_value))

    all_ints_in_band = list(range(lower_bound, upper_bound + 1))

    if len(all_ints_in_band) <= target_count:
        return all_ints_in_band

    # Sample up to target_count evenly across available integers in the band
    selected: List[int] = []
    n = len(all_ints_in_band)
    for i in range(target_count):
        idx = int(round(i * (n - 1) / (target_count - 1)))
        selected.append(all_ints_in_band[idx])

    # Deduplicate in case rounding produced duplicates
    dedup_selected: List[int] = []
    seen = set()
    for v in selected:
        if v not in seen:
            seen.add(v)
            dedup_selected.append(v)

    return dedup_selected


def parse_phase5_best_params() -> Dict[str, Any]:
    """Parse Phase 5 best parameters from results files."""
    # Try to load from sensitivity analysis first
    sensitivity_path = Path("optimization/results/phase5_sensitivity_analysis.json")
    if sensitivity_path.exists():
        try:
            with open(sensitivity_path, 'r') as f:
                data = json.load(f)
            
            # Check if sensitivity analysis has real data
            if "best_values" in data and data["best_values"] != "[Generated by script]":
                logger.info("Using Phase 5 best values from sensitivity analysis")
                return data["best_values"]
        except (json.JSONDecodeError, KeyError) as e:
            logger.warning(f"Could not parse sensitivity analysis best values: {e}")
    
    # Fall back to top 10 results file
    top10_path = Path("optimization/results/phase5_filters_results_top_10.json")
    if top10_path.exists():
        try:
            with open(top10_path, 'r') as f:
                data = json.load(f)
            
            # Get rank 1 parameters
            if isinstance(data, list) and len(data) > 0:
                rank1_params = data[0].get("parameters", {})
                if rank1_params:
                    # Remove run_id if present
                    rank1_params = {k: v for k, v in rank1_params.items() if k != "run_id"}
                    logger.info("Using Phase 5 best values from top 10 results (rank 1)")
                    return rank1_params
        except (json.JSONDecodeError, KeyError, IndexError) as e:
            logger.warning(f"Could not parse top 10 results: {e}")
    
    # Final fallback to hardcoded values
    logger.warning("Using hardcoded Phase 5 best values as fallback")
    return {
        "fast_period": 42,
        "slow_period": 270,
        "crossover_threshold_pips": 0.35,
        "stop_loss_pips": 35,
        "take_profit_pips": 50,
        "trailing_stop_activation_pips": 22,
        "trailing_stop_distance_pips": 12,
        "dmi_enabled": True,
        "dmi_period": 10,
        "stoch_period_k": 18,
        "stoch_period_d": 3,
        "stoch_bullish_threshold": 30,
        "stoch_bearish_threshold": 65
    }


def load_phase6_config(phase6_yaml_path: Path) -> Dict[str, Any]:
    """Load existing Phase 6 YAML configuration."""
    try:
        with open(phase6_yaml_path, 'r') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError:
        raise ValueError(f"Phase 6 YAML file not found: {phase6_yaml_path}")
    except yaml.YAMLError as e:
        raise ValueError(f"Invalid YAML in Phase 6 configuration: {e}")
    
    logger.info(f"Loaded Phase 6 configuration from {phase6_yaml_path}")
    return config


def update_parameters_section(sensitivity_data: Dict[str, Any], phase5_best_params: Dict[str, Any]) -> Dict[str, Any]:
    """Build new parameters section with only the 4 sensitive parameters."""
    config_suggestion = sensitivity_data["phase6_configuration_suggestion"]
    params_to_refine = config_suggestion["parameters_to_refine"]
    params_to_fix = config_suggestion["parameters_to_fix"]
    
    # Get top 4 sensitive parameters with their scores
    top_4_params = sensitivity_data.get("top_4_sensitive_parameters", [])
    
    new_parameters = {}
    
    for param_name in params_to_refine:
        # Get best value from params_to_fix or fallback to Phase 5 best
        best_value = params_to_fix.get(param_name)
        if best_value is None:
            best_value = phase5_best_params.get(param_name)
            if best_value is None:
                logger.warning(f"No best value found for {param_name}, using default")
                continue
        
        # Calculate ±10% range with exactly 4 values per parameter
        values = calculate_parameter_range(best_value, param_name, target_count=4)
        
        # Find sensitivity score for rationale
        sensitivity_score = "N/A"
        for param_info in top_4_params:
            if param_info.get("parameter_name") == param_name:
                sensitivity_score = param_info.get("sensitivity_score", "N/A")
                break
        
        new_parameters[param_name] = {
            "values": values,
            "rationale": f"High sensitivity score ({sensitivity_score}) - significant impact on Sharpe ratio",
            "phase5_best": best_value
        }
        
        logger.info(f"Added parameter {param_name}: {len(values)} values around {best_value}")
    
    return new_parameters


def update_fixed_section(sensitivity_data: Dict[str, Any], original_config: Dict[str, Any], phase5_best_params: Dict[str, Any]) -> Dict[str, Any]:
    """Build new fixed section with the 7 non-sensitive parameters plus existing fixed parameters."""
    config_suggestion = sensitivity_data["phase6_configuration_suggestion"]
    params_to_fix = config_suggestion["parameters_to_fix"]
    
    # Start with existing fixed parameters
    new_fixed = original_config.get("fixed", {}).copy()
    
    # Add the 7 non-sensitive parameters
    for param_name, best_value in params_to_fix.items():
        new_fixed[param_name] = best_value
        logger.info(f"Fixed parameter {param_name} at {best_value}")
    
    return new_fixed


def calculate_total_combinations(parameters: Dict[str, Any]) -> int:
    """Calculate total combinations by multiplying the length of values lists."""
    total = 1
    for param_name, param_config in parameters.items():
        values = param_config.get("values", [])
        total *= len(values)
        logger.debug(f"Parameter {param_name}: {len(values)} values")
    
    return total


def update_yaml_comments(config: Dict[str, Any], total_combinations: int, params_to_refine: List[str], params_to_fix: Dict[str, Any]) -> str:
    # Build lists
    refined_list = "\n".join([f"#   - {param}" for param in params_to_refine])
    fixed_list = "\n".join([f"#   - {param}: {value}" for param, value in params_to_fix.items()])
    # Keep existing combination calc placeholder (will be accurate when all have 4 values)
    combination_calc = " × ".join(["4"] * len(params_to_refine)) + f" = {total_combinations}"
    # Provenance
    generated_by = str(Path(__file__).as_posix())
    generated_on = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    source = "optimization/results/phase5_sensitivity_analysis.json"

    header = f"""# Phase 6: Parameter Refinement and Sensitivity Analysis
# Selective refinement of most sensitive parameters from Phases 3-5 using multi-objective Pareto optimization
# 
# Generated by: {generated_by}
# Generated on: {generated_on}
# Source: {source}
# 
# This configuration uses SELECTIVE refinement (not full ±10% grid on all parameters) to avoid combinatorial explosion.
# Total combinations: {total_combinations:,} (based on selective parameter refinement)
# 
# Prerequisites: Phase 5 must complete successfully
# Phase 5 Best Results reference:
#   - All parameters from Phase 5 rank 1 (fast=42, slow=270, threshold=0.35, SL=35, TP=50, TA=22, TD=12, dmi_enabled=true, dmi_period=10, stoch_k=18, stoch_d=3, stoch_bullish=30, stoch_bearish=65)
#   - sharpe_ratio: 0.4779 (11.6% improvement over Phase 4)
#   - Source: optimization/results/phase5_filters_results_top_10.json
# 
# Key Insight: Phase 5 ranks 1-6 have identical Sharpe (0.4779) with dmi_enabled varying, suggesting DMI has minimal impact
# 
# Parameters being refined ({len(params_to_refine)} parameters):
{refined_list}
# 
# Parameters fixed at Phase 5 best values ({len(params_to_fix)} parameters):
{fixed_list}
# 
# Combination calculation: {combination_calc}
# 
# Usage example with Pareto flag:
#   python optimization/grid_search.py \
#     --config optimization/configs/phase6_refinement.yaml \
#     --objective sharpe_ratio \
#     --pareto sharpe_ratio total_pnl max_drawdown \
#     --workers 8 \
#     --output optimization/results/phase6_refinement_results.csv \
#     --no-resume \
#     --verbose
# 
# Expected runtime: 4-6 hours with 8 workers ({total_combinations:,} backtests)
# Phase context: Fifth optimization phase, results will be used for Phase 7 walk-forward validation
# 
# Success criteria:
#   - Maintain Phase 5 Sharpe ratio (0.4779) or improve
#   - Generate robust Pareto frontier with 10-20 non-dominated solutions
#   - Identify 5 diverse parameter sets balancing Sharpe, PnL, and drawdown
#   - Comprehensive sensitivity analysis showing parameter stability
#   - Top 5 parameter sets ready for walk-forward validation
"""
    return header


def write_updated_config(config: Dict[str, Any], output_path: Path, total_combinations: int, params_to_refine: List[str], params_to_fix: Dict[str, Any]) -> None:
    header = update_yaml_comments(config, total_combinations, params_to_refine, params_to_fix)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(header)
        f.write("\n")
        yaml.dump(config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
    logger.info(f"Updated configuration written to {output_path}")


def validate_updated_config(config_path: Path) -> bool:
    """Validate the updated YAML by attempting to load it with grid_search.py's load_grid_config function."""
    try:
        # Import grid_search module to use its validation
        import sys
        sys.path.append(str(Path(__file__).parent.parent))
        from grid_search import load_grid_config
        
        # Try to load the configuration
        opt_config, param_ranges, fixed_params = load_grid_config(config_path)
        
        # Pre-check that param_ranges doesn't include boolean parameters
        boolean_params = ["dmi_enabled", "stoch_enabled"]
        for param_name in param_ranges.keys():
            if param_name in boolean_params:
                logger.error(f"Parameter {param_name} should not be in refinement grid (boolean type)")
                return False
        
        # Validate parameter types
        for param_name, param_config in param_ranges.items():
            values = param_config.get("values", [])
            if not values:
                logger.error(f"Parameter {param_name} has no values")
                return False
            
            # Check value types (no boolean parameters should be in refinement grid)
            for value in values:
                if param_name in ["crossover_threshold_pips"]:
                    if not isinstance(value, (int, float)):
                        logger.error(f"Parameter {param_name} values must be numeric")
                        return False
                else:
                    if not isinstance(value, int):
                        logger.error(f"Parameter {param_name} values must be integers")
                        return False
        
        logger.info("Configuration validation successful")
        return True
        
    except Exception as e:
        logger.error(f"Configuration validation failed: {e}")
        return False


def generate_update_summary(sensitivity_data: Dict[str, Any], total_combinations: int, params_to_refine: List[str], params_to_fix: Dict[str, Any]) -> str:
    """Generate a summary report showing the changes made."""
    top_4_params = sensitivity_data.get("top_4_sensitive_parameters", [])
    
    summary = f"""
Phase 6 Configuration Update Summary
====================================

Parameters moved to fixed section ({len(params_to_fix)} parameters):
"""
    
    for param_name, value in params_to_fix.items():
        summary += f"  - {param_name}: {value}\n"
    
    summary += f"\nParameters kept for refinement ({len(params_to_refine)} parameters):\n"
    
    for param_info in top_4_params:
        param_name = param_info.get("parameter_name", "Unknown")
        sensitivity_score = param_info.get("sensitivity_score", "N/A")
        summary += f"  - {param_name}: sensitivity score {sensitivity_score}\n"
    
    summary += f"""
Combination count reduction:
  - Before: 5,906,250 combinations (11 parameters)
  - After: {total_combinations:,} combinations (4 parameters)
  - Reduction: {((5906250 - total_combinations) / 5906250 * 100):.1f}%

Estimated runtime reduction:
  - Before: 20-40 hours (5.9M combinations)
  - After: 4-6 hours ({total_combinations:,} combinations)
  - Reduction: ~75-85% faster

Top 4 sensitive parameters identified by Phase 5 sensitivity analysis:
"""
    
    for i, param_info in enumerate(top_4_params, 1):
        param_name = param_info.get("parameter_name", "Unknown")
        sensitivity_score = param_info.get("sensitivity_score", "N/A")
        rationale = param_info.get("rationale", "No rationale provided")
        summary += f"  {i}. {param_name}: {sensitivity_score} - {rationale}\n"
    
    return summary


def main():
    """Main function to orchestrate the Phase 6 configuration update."""
    parser = argparse.ArgumentParser(description="Update Phase 6 configuration based on Phase 5 sensitivity analysis")
    parser.add_argument("--sensitivity-json", default="optimization/results/phase5_sensitivity_analysis.json",
                       help="Path to Phase 5 sensitivity analysis JSON file")
    parser.add_argument("--phase6-yaml", default="optimization/configs/phase6_refinement.yaml",
                       help="Path to Phase 6 YAML configuration file")
    parser.add_argument("--output-yaml", default=None,
                       help="Path to output YAML file (defaults to same as phase6-yaml)")
    parser.add_argument("--dry-run", action="store_true",
                       help="Show what would be changed without writing files")
    parser.add_argument("--verbose", action="store_true",
                       help="Enable verbose logging")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Set output path
    output_path = Path(args.output_yaml) if args.output_yaml else Path(args.phase6_yaml)
    
    try:
        # Load sensitivity analysis
        logger.info("Loading Phase 5 sensitivity analysis...")
        sensitivity_data = load_sensitivity_analysis(Path(args.sensitivity_json))
        
        # Load Phase 6 configuration
        logger.info("Loading Phase 6 configuration...")
        phase6_config = load_phase6_config(Path(args.phase6_yaml))
        
        # Parse Phase 5 best parameters from results files
        phase5_best_params = parse_phase5_best_params()
        
        # Update parameters section
        logger.info("Updating parameters section...")
        new_parameters = update_parameters_section(sensitivity_data, phase5_best_params)
        
        # Update fixed section
        logger.info("Updating fixed section...")
        new_fixed = update_fixed_section(sensitivity_data, phase6_config, phase5_best_params)
        
        # Calculate total combinations
        total_combinations = calculate_total_combinations(new_parameters)
        logger.info(f"Total combinations: {total_combinations:,}")
        
        # Validate combination count
        if total_combinations < 200:
            logger.warning(f"Combination count ({total_combinations:,}) is below recommended minimum (200)")
        elif total_combinations > 300:
            logger.warning(f"Combination count ({total_combinations:,}) is above recommended maximum (300)")
        else:
            logger.info(f"Combination count ({total_combinations:,}) is within recommended range (200-300)")
        
        # Build updated configuration
        updated_config = {
            "optimization": phase6_config.get("optimization", {}),
            "parameters": new_parameters,
            "fixed": new_fixed
        }
        
        # Get parameter lists for summary
        config_suggestion = sensitivity_data["phase6_configuration_suggestion"]
        params_to_refine = config_suggestion["parameters_to_refine"]
        params_to_fix = config_suggestion["parameters_to_fix"]
        
        # Generate summary
        summary = generate_update_summary(sensitivity_data, total_combinations, params_to_refine, params_to_fix)
        
        if args.dry_run:
            logger.info("DRY RUN - No files will be modified")
            print(summary)
            return 0
        
        # Write updated configuration
        logger.info("Writing updated configuration...")
        write_updated_config(updated_config, output_path, total_combinations, params_to_refine, params_to_fix)
        
        # Validate updated configuration
        logger.info("Validating updated configuration...")
        if not validate_updated_config(output_path):
            logger.error("Configuration validation failed")
            return 1
        
        # Print summary
        print(summary)
        logger.info("Phase 6 configuration update completed successfully")
        return 0
        
    except Exception as e:
        logger.error(f"Error updating Phase 6 configuration: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
